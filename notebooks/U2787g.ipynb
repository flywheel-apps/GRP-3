{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports and logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import json\n",
    "import jsonschema\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import logging\n",
    "import pytz\n",
    "import pydicom\n",
    "import string\n",
    "import tzlocal\n",
    "import logging\n",
    "import zipfile\n",
    "import datetime\n",
    "import argparse\n",
    "import nibabel\n",
    "from fnmatch import fnmatch\n",
    "from pprint import pprint\n",
    "\n",
    "logging.basicConfig()\n",
    "log = logging.getLogger('U2787g')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_session_label(dcm):\n",
    "    \"\"\"\n",
    "    Switch on manufacturer and either pull out the StudyID or the StudyInstanceUID\n",
    "    \"\"\"\n",
    "    session_label = ''\n",
    "    if ( dcm.get('Manufacturer') and (dcm.get('Manufacturer').find('GE') != -1 or dcm.get('Manufacturer').find('Philips') != -1 ) and dcm.get('StudyID')):\n",
    "        session_label = dcm.get('StudyID')\n",
    "    else:\n",
    "        session_label = dcm.get('StudyInstanceUID')\n",
    "\n",
    "    return session_label\n",
    "\n",
    "\n",
    "def validate_timezone(zone):\n",
    "    # pylint: disable=missing-docstring\n",
    "    if zone is None:\n",
    "        zone = tzlocal.get_localzone()\n",
    "    else:\n",
    "        try:\n",
    "            zone = pytz.timezone(zone.zone)\n",
    "        except pytz.UnknownTimeZoneError:\n",
    "            zone = None\n",
    "    return zone\n",
    "\n",
    "\n",
    "def parse_patient_age(age):\n",
    "    \"\"\"\n",
    "    Parse patient age from string.\n",
    "    convert from 70d, 10w, 2m, 1y to datetime.timedelta object.\n",
    "    Returns age as duration in seconds.\n",
    "    \"\"\"\n",
    "    if age == 'None' or not age:\n",
    "        return None\n",
    "\n",
    "    conversion = {  # conversion to days\n",
    "        'Y': 365.25,\n",
    "        'M': 30,\n",
    "        'W': 7,\n",
    "        'D': 1,\n",
    "    }\n",
    "    scale = age[-1:]\n",
    "    value = age[:-1]\n",
    "    if scale not in conversion.keys():\n",
    "        # Assume years\n",
    "        scale = 'Y'\n",
    "        value = age\n",
    "\n",
    "    age_in_seconds = datetime.timedelta(int(value) * conversion.get(scale)).total_seconds()\n",
    "\n",
    "    # Make sure that the age is reasonable\n",
    "    if not age_in_seconds or age_in_seconds <= 0:\n",
    "        age_in_seconds = None\n",
    "\n",
    "    return age_in_seconds\n",
    "\n",
    "\n",
    "def timestamp(date, time, timezone):\n",
    "    \"\"\"\n",
    "    Return datetime formatted string\n",
    "    \"\"\"\n",
    "    if date and time and timezone:\n",
    "        # return datetime.datetime.strptime(date + time[:6], '%Y%m%d%H%M%S')\n",
    "        try:\n",
    "            return timezone.localize(datetime.datetime.strptime(date + time[:6], '%Y%m%d%H%M%S'), timezone)\n",
    "        except:\n",
    "            log.warning('Failed to create timestamp!')\n",
    "            log.info(date)\n",
    "            log.info(time)\n",
    "            log.info(timezone)\n",
    "            return None\n",
    "    return None\n",
    "\n",
    "\n",
    "def get_timestamp(dcm, timezone):\n",
    "    \"\"\"\n",
    "    Parse Study Date and Time, return acquisition and session timestamps\n",
    "    \"\"\"\n",
    "    if hasattr(dcm, 'StudyDate') and hasattr(dcm, 'StudyTime'):\n",
    "        study_date = dcm.StudyDate\n",
    "        study_time = dcm.StudyTime\n",
    "    elif hasattr(dcm, 'StudyDateTime'):\n",
    "        study_date = dcm.StudyDateTime[0:8]\n",
    "        study_time = dcm.StudyDateTime[8:]\n",
    "    else:\n",
    "        study_date = None\n",
    "        study_time = None\n",
    "\n",
    "    if hasattr(dcm, 'AcquisitionDate') and hasattr(dcm, 'AcquisitionTime'):\n",
    "        acquitision_date = dcm.AcquisitionDate\n",
    "        acquisition_time = dcm.AcquisitionTime\n",
    "    elif hasattr(dcm, 'AcquisitionDateTime'):\n",
    "        acquitision_date = dcm.AcquisitionDateTime[0:8]\n",
    "        acquisition_time = dcm.AcquisitionDateTime[8:]\n",
    "    # The following allows the timestamps to be set for ScreenSaves\n",
    "    elif hasattr(dcm, 'ContentDate') and hasattr(dcm, 'ContentTime'):\n",
    "        acquitision_date = dcm.ContentDate\n",
    "        acquisition_time = dcm.ContentTime\n",
    "    else:\n",
    "        acquitision_date = None\n",
    "        acquisition_time = None\n",
    "\n",
    "    session_timestamp = timestamp(dcm.StudyDate, dcm.StudyTime, timezone)\n",
    "    acquisition_timestamp = timestamp(acquitision_date, acquisition_time, timezone)\n",
    "\n",
    "    if session_timestamp:\n",
    "        if session_timestamp.tzinfo is None:\n",
    "            log.info('no tzinfo found, using UTC...')\n",
    "            session_timestamp = pytz.timezone('UTC').localize(session_timestamp)\n",
    "        session_timestamp = session_timestamp.isoformat()\n",
    "    else:\n",
    "        session_timestamp = ''\n",
    "    if acquisition_timestamp:\n",
    "        if acquisition_timestamp.tzinfo is None:\n",
    "            log.info('no tzinfo found, using UTC')\n",
    "            acquisition_timestamp = pytz.timezone('UTC').localize(acquisition_timestamp)\n",
    "        acquisition_timestamp = acquisition_timestamp.isoformat()\n",
    "    else:\n",
    "        acquisition_timestamp = ''\n",
    "    return session_timestamp, acquisition_timestamp\n",
    "\n",
    "\n",
    "def get_sex_string(sex_str):\n",
    "    \"\"\"\n",
    "    Return male or female string.\n",
    "    \"\"\"\n",
    "    if sex_str == 'M':\n",
    "        sex = 'male'\n",
    "    elif sex_str == 'F':\n",
    "        sex = 'female'\n",
    "    else:\n",
    "        sex = ''\n",
    "    return sex\n",
    "\n",
    "\n",
    "def assign_type(s):\n",
    "    \"\"\"\n",
    "    Sets the type of a given input.\n",
    "    \"\"\"\n",
    "    if type(s) == pydicom.valuerep.PersonName or type(s) == pydicom.valuerep.PersonName3 or type(s) == pydicom.valuerep.PersonNameBase:\n",
    "        return format_string(s)\n",
    "    if type(s) == list or type(s) == pydicom.multival.MultiValue:\n",
    "        try:\n",
    "            return [ int(x) for x in s ]\n",
    "        except ValueError:\n",
    "            try:\n",
    "                return [ float(x) for x in s ]\n",
    "            except ValueError:\n",
    "                return [ format_string(x) for x in s if len(x) > 0 ]\n",
    "    else:\n",
    "        s = str(s)\n",
    "        try:\n",
    "            return int(s)\n",
    "        except ValueError:\n",
    "            try:\n",
    "                return float(s)\n",
    "            except ValueError:\n",
    "                return format_string(s)\n",
    "\n",
    "\n",
    "def format_string(in_string):\n",
    "    formatted = re.sub(r'[^\\x00-\\x7f]',r'', str(in_string)) # Remove non-ascii characters\n",
    "    formatted = ''.join(filter(lambda x: x in string.printable, formatted))\n",
    "    if len(formatted) == 1 and formatted == '?':\n",
    "        formatted = None\n",
    "    return formatted#.encode('utf-8').strip()\n",
    "\n",
    "\n",
    "def get_seq_data(sequence, ignore_keys):\n",
    "    seq_dict = {}\n",
    "    for seq in sequence:\n",
    "        for s_key in seq.dir():\n",
    "            s_val = getattr(seq, s_key, '')\n",
    "            if type(s_val) is pydicom.UID.UID or s_key in ignore_keys:\n",
    "                continue\n",
    "\n",
    "            if type(s_val) == pydicom.sequence.Sequence:\n",
    "                _seq = get_seq_data(s_val, ignore_keys)\n",
    "                seq_dict[s_key] = _seq\n",
    "                continue\n",
    "\n",
    "            if type(s_val) == str:\n",
    "                s_val = format_string(s_val)\n",
    "            else:\n",
    "                s_val = assign_type(s_val)\n",
    "\n",
    "            if s_val:\n",
    "                seq_dict[s_key] = s_val\n",
    "\n",
    "    return seq_dict\n",
    "\n",
    "\n",
    "def get_pydicom_header(dcm):\n",
    "    # Extract the header values\n",
    "    header = {}\n",
    "    exclude_tags = ['[Unknown]', \n",
    "                    'PixelData', \n",
    "                    'Pixel Data',  \n",
    "                    '[User defined data]', \n",
    "                    '[Protocol Data Block (compressed)]', \n",
    "                    '[Histogram tables]', \n",
    "                    '[Unique image iden]']\n",
    "    tags = dcm.dir()\n",
    "    for tag in tags:\n",
    "        try:\n",
    "            if (tag not in exclude_tags) and ( type(dcm.get(tag)) != pydicom.sequence.Sequence ):\n",
    "                value = dcm.get(tag)\n",
    "                if value or value == 0: # Some values are zero\n",
    "                    # Put the value in the header\n",
    "                    if type(value) == str and len(value) < 10240: # Max pydicom field length\n",
    "                        header[tag] = format_string(value)\n",
    "                    else:\n",
    "                        header[tag] = assign_type(value)\n",
    "                else:\n",
    "                    log.debug('No value found for tag: ' + tag)\n",
    "\n",
    "            if type(dcm.get(tag)) == pydicom.sequence.Sequence:\n",
    "                seq_data = get_seq_data(dcm.get(tag), exclude_tags)\n",
    "                # Check that the sequence is not empty\n",
    "                if seq_data:\n",
    "                    header[tag] = seq_data\n",
    "        except:\n",
    "            log.debug('Failed to get ' + tag)\n",
    "            pass\n",
    "    return header\n",
    "\n",
    "\n",
    "def get_csa_header(dcm):\n",
    "    exclude_tags = ['PhoenixZIP', 'SrMsgBuffer']\n",
    "    header = {}\n",
    "    try:\n",
    "        raw_csa_header = nibabel.nicom.dicomwrappers.SiemensWrapper(dcm).csa_header\n",
    "        tags = raw_csa_header['tags']\n",
    "    except:\n",
    "        log.warning('Failed to parse csa header!')\n",
    "        return header\n",
    "\n",
    "    for tag in tags:\n",
    "        if not raw_csa_header['tags'][tag]['items'] or tag in exclude_tags:\n",
    "            log.debug('Skipping : %s' % tag)\n",
    "            pass\n",
    "        else:\n",
    "            value = raw_csa_header['tags'][tag]['items']\n",
    "            if len(value) == 1:\n",
    "                value = value[0]\n",
    "                if type(value) == str and ( len(value) > 0 and len(value) < 1024 ):\n",
    "                    header[format_string(tag)] = format_string(value)\n",
    "                else:\n",
    "                    header[format_string(tag)] = assign_type(value)\n",
    "            else:\n",
    "                header[format_string(tag)] = assign_type(value)\n",
    "\n",
    "    return header\n",
    "\n",
    "\n",
    "def get_classification_from_string(value):\n",
    "    result = {}\n",
    "\n",
    "    parts = re.split(r'\\s*,\\s*', value)\n",
    "    last_key = None\n",
    "    for part in parts:\n",
    "        key_value = re.split(r'\\s*:\\s*', part)\n",
    "\n",
    "        if len(key_value) == 2:\n",
    "            last_key = key = key_value[0]\n",
    "            value = key_value[1]\n",
    "        else:\n",
    "            if last_key:\n",
    "                key = last_key\n",
    "            else:\n",
    "                log.warning('Unknown classification format: {0}'.format(part))\n",
    "                key = 'Custom'\n",
    "            value = part\n",
    "\n",
    "        if key not in result:\n",
    "            result[key] = []\n",
    "\n",
    "        result[key].append(value)\n",
    "\n",
    "    return result\n",
    "\n",
    "\n",
    "def validate_against_template(input_dict, template, error_log_path):\n",
    "    \"\"\"\n",
    "    This is a function for validating a dictionary against a template. Given\n",
    "    an input_dict and a template object, it will create a JSON schema validator\n",
    "    and construct an object that is a list of error dictionaries. It will write a\n",
    "    JSON file to the specified error_log_path and return the validation_errors object as\n",
    "    well as log each error.message to log.errors\n",
    "\n",
    "    :param input_dict: a dictionary of DICOM header data to be validated\n",
    "    :param template: a template dictionary to validate against\n",
    "    :param error_log_path: the path to which to write error log JSON\n",
    "    :return: validation_errors, an object containing information on validation errors\n",
    "    \"\"\"\n",
    "    # Initialize json schema validator\n",
    "    validator = jsonschema.Draft7Validator(template)\n",
    "    # Initialize list object for storing validation errors\n",
    "    validation_errors = []\n",
    "    for error in sorted(validator.iter_errors(input_dict), key=str):\n",
    "        # Create a temporary dictionary for the individual error\n",
    "        tmp_dict = {}\n",
    "        # Get error type\n",
    "        tmp_dict['error_type'] = error.validator\n",
    "        # Get error message and log it\n",
    "        tmp_dict['error_message'] = error.message\n",
    "        log.error(error.message)\n",
    "        # Required field errors are a little special and need to be handled\n",
    "        # separately to get the field. We don't get the schema because it\n",
    "        # will print the entire template schema\n",
    "        if error.validator == \"required\":\n",
    "            # Get the item failing validation from the error message\n",
    "            tmp_dict['item'] = 'info.' + error.message.split(\"'\")[1]\n",
    "        # Get additional information for pattern and type errors\n",
    "        elif error.validator in (\"pattern\", \"type\"):\n",
    "            # Get the value of the field that failed validation\n",
    "            tmp_dict['error_value'] = error.instance\n",
    "            # Get the field that failed validation\n",
    "            tmp_dict['item'] = 'info.' + str(error.path.pop())\n",
    "            # Get the schema object used to validate in failed validation\n",
    "            tmp_dict['schema'] = error.schema\n",
    "        elif error.validator == \"anyOf\":\n",
    "            tmp_dict['schema'] = {\"anyOf\": error.schema['anyOf']}\n",
    "        else:\n",
    "            pass\n",
    "        # Append individual error object to the return validation_errors object\n",
    "        validation_errors.append(tmp_dict)\n",
    "\n",
    "    with open(error_log_path, 'w') as outfile:\n",
    "        json.dump(validation_errors, outfile, separators=(', ', ': '), sort_keys=True, indent=4)\n",
    "    return validation_errors\n",
    "\n",
    "\n",
    "def dicom_to_json(zip_file_path, outbase, timezone):\n",
    "    # Check for input file path\n",
    "    if not os.path.exists(zip_file_path):\n",
    "        log.debug('could not find %s' % zip_file_path)\n",
    "        log.debug('checking input directory ...')\n",
    "        if os.path.exists(os.path.join('/input', zip_file_path)):\n",
    "            zip_file_path = os.path.join('/input', zip_file_path)\n",
    "            log.debug('found %s' % zip_file_path)\n",
    "\n",
    "    if not outbase:\n",
    "        outbase = '/flywheel/v0/output'\n",
    "        log.info('setting outbase to %s' % outbase)\n",
    "\n",
    "    # Extract the last file in the zip to /tmp/ and read it\n",
    "    dcm = []\n",
    "    if zipfile.is_zipfile(zip_file_path):\n",
    "        zip = zipfile.ZipFile(zip_file_path)\n",
    "        num_files = len(zip.namelist())\n",
    "        for n in range((num_files - 1), -1, -1):\n",
    "            dcm_path = zip.extract(zip.namelist()[n], '/tmp')\n",
    "            if os.path.isfile(dcm_path):\n",
    "                try:\n",
    "                    log.info('reading %s' % dcm_path)\n",
    "                    dcm = pydicom.read_file(dcm_path)\n",
    "                    # Here we check for the Raw Data Storage SOP Class, if there\n",
    "                    # are other pydicom files in the zip then we read the next one,\n",
    "                    # if this is the only class of pydicom in the file, we accept\n",
    "                    # our fate and move on.\n",
    "                    if dcm.get('SOPClassUID') == 'Raw Data Storage' and n != range((num_files - 1), -1, -1)[-1]:\n",
    "                        continue\n",
    "                    else:\n",
    "                        break\n",
    "                except:\n",
    "                    pass\n",
    "            else:\n",
    "                log.warning('%s does not exist!' % dcm_path)\n",
    "    else:\n",
    "        log.info('Not a zip. Attempting to read %s directly' % os.path.basename(zip_file_path))\n",
    "        dcm = pydicom.read_file(zip_file_path)\n",
    "\n",
    "    if not dcm:\n",
    "        log.warning('dcm is empty!!!')\n",
    "        os.sys.exit(1)\n",
    "\n",
    "    # Build metadata\n",
    "    metadata = {}\n",
    "\n",
    "    # Session metadata\n",
    "    metadata['session'] = {}\n",
    "    session_timestamp, acquisition_timestamp = get_timestamp(dcm, timezone);\n",
    "    if session_timestamp:\n",
    "        metadata['session']['timestamp'] = session_timestamp\n",
    "    if hasattr(dcm, 'OperatorsName') and dcm.get('OperatorsName'):\n",
    "        metadata['session']['operator'] = format_string(dcm.get('OperatorsName'))\n",
    "    session_label = get_session_label(dcm)\n",
    "    if session_label:\n",
    "        metadata['session']['label'] = session_label\n",
    "\n",
    "    # Subject Metadata\n",
    "    metadata['session']['subject'] = {}\n",
    "    if hasattr(dcm, 'PatientSex') and get_sex_string(dcm.get('PatientSex')):\n",
    "        metadata['session']['subject']['sex'] = get_sex_string(dcm.get('PatientSex'))\n",
    "    if hasattr(dcm, 'PatientAge') and dcm.get('PatientAge'):\n",
    "        try:\n",
    "            age = parse_patient_age(dcm.get('PatientAge'))\n",
    "            if age:\n",
    "                metadata['session']['subject']['age'] = int(age)\n",
    "        except:\n",
    "            pass\n",
    "    if hasattr(dcm, 'PatientName') and dcm.get('PatientName').given_name:\n",
    "        # If the first name or last name field has a space-separated string, and one or the other field is not\n",
    "        # present, then we assume that the operator put both first and last names in that one field. We then\n",
    "        # parse that field to populate first and last name.\n",
    "        metadata['session']['subject']['firstname'] = str(format_string(dcm.get('PatientName').given_name))\n",
    "        if not dcm.get('PatientName').family_name:\n",
    "            name = format_string(dcm.get('PatientName').given_name.split(' '))\n",
    "            if len(name) == 2:\n",
    "                first = name[0]\n",
    "                last = name[1]\n",
    "                metadata['session']['subject']['lastname'] = str(last)\n",
    "                metadata['session']['subject']['firstname'] = str(first)\n",
    "    if hasattr(dcm, 'PatientName') and dcm.get('PatientName').family_name:\n",
    "        metadata['session']['subject']['lastname'] = str(format_string(dcm.get('PatientName').family_name))\n",
    "        if not dcm.get('PatientName').given_name:\n",
    "            name = format_string(dcm.get('PatientName').family_name.split(' '))\n",
    "            if len(name) == 2:\n",
    "                first = name[0]\n",
    "                last = name[1]\n",
    "                metadata['session']['subject']['lastname'] = str(last)\n",
    "                metadata['session']['subject']['firstname'] = str(first)\n",
    "\n",
    "    # File classification\n",
    "    pydicom_file = {}\n",
    "    pydicom_file['name'] = os.path.basename(zip_file_path)\n",
    "    pydicom_file['modality'] = format_string(dcm.get('Modality', 'MR'))\n",
    "\n",
    "    # Acquisition metadata\n",
    "    metadata['acquisition'] = {}\n",
    "    if hasattr(dcm, 'Modality') and dcm.get('Modality'):\n",
    "        metadata['acquisition']['instrument'] = format_string(dcm.get('Modality'))\n",
    "\n",
    "    series_desc = format_string(dcm.get('SeriesDescription', ''))\n",
    "    if series_desc:\n",
    "        metadata['acquisition']['label'] = series_desc\n",
    "\n",
    "    if acquisition_timestamp:\n",
    "        metadata['acquisition']['timestamp'] = acquisition_timestamp\n",
    "\n",
    "    # Acquisition metadata from pydicom header\n",
    "    pydicom_file['info'] = get_pydicom_header(dcm)\n",
    "\n",
    "    # Validate header data\n",
    "    error_filepath = os.path.join(output_folder, 'error.log.json')\n",
    "    validation_errors = validate_against_template(pydicom_file['info'], json_template, error_filepath)\n",
    "    if validation_errors:\n",
    "        metadata['acquisition']['tags'] = ['error']\n",
    "\n",
    "    # Append the pydicom_file to the files array\n",
    "    metadata['acquisition']['files'] = [pydicom_file]\n",
    "\n",
    "    # Acquisition metadata from pydicom header\n",
    "    metadata['acquisition']['metadata'] = get_pydicom_header(dcm)\n",
    "    if dcm.get('Manufacturer') == 'SIEMENS':\n",
    "        csa_header = get_csa_header(dcm)\n",
    "        if csa_header:\n",
    "            metadata['acquisition']['metadata']['CSAHeader'] = csa_header\n",
    "\n",
    "    # Write out the metadata to file (.metadata.json)\n",
    "    metafile_outname = os.path.join(os.path.dirname(outbase), '.metadata.json')\n",
    "    with open(metafile_outname, 'w') as metafile:\n",
    "        json.dump(metadata, metafile, separators=(', ', ': '), sort_keys=True, indent=4)\n",
    "\n",
    "    # Show the metadata\n",
    "    pprint(metadata)\n",
    "\n",
    "    return metafile_outname"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load in JSON Schema template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'template_filepath' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-e5240b8a198e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtemplate_filepath\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtemplate_data\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mtemplate_json\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtemplate_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'template_filepath' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "with open(template_filepath) as template_data:\n",
    "    template_json = json.load(template_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dictionary = {\n",
    "    \"Modality\": \"CT\",\n",
    "    \"ImageType\": \"SCREEN SAVE\",\n",
    "    \"PatientID\": \"55555\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validate_against_template(test_dictionary, template_json, \"error.log.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize json schema validator\n",
    "validator = jsonschema.Draft7Validator(template_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'validator' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-45aad781f2b3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0merror\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalidator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miter_errors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_dictionary\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalidator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0merror\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalidator\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"anyOf\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mschema\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'validator' is not defined"
     ]
    }
   ],
   "source": [
    "for error in sorted(validator.iter_errors(test_dictionary), key=str):\n",
    "    print(error.validator)\n",
    "    if error.validator == \"anyOf\":\n",
    "        print(error.schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "template_filepath = \"U2787g_template\"\n",
    "# Configure timezone and dicom filepath\n",
    "timezone = validate_timezone(tzlocal.get_localzone())\n",
    "zip_file_path = \"A.zip\"\n",
    "outbase = os.getcwd()\n",
    "output_folder = os.getcwd()\n",
    "# Import JSON template\n",
    "with open(template_filepath) as template_data:\n",
    "    json_template = json.load(template_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:U2787g:'737178' does not match '^[0-9]{5}$'\n",
      "ERROR:U2787g:['ORIGINAL', 'PRIMARY', 'OTHER'] is not of type 'string'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'acquisition': {'files': [{'info': {'AccessionNumber': '039208195',\n",
      "                                     'AcquisitionDate': '20050623',\n",
      "                                     'AcquisitionMatrix': [0, 256, 256, 0],\n",
      "                                     'AcquisitionNumber': 1,\n",
      "                                     'AcquisitionTime': '083051',\n",
      "                                     'AdditionalPatientHistory': 'RESEARCH PT',\n",
      "                                     'AngioFlag': 'N',\n",
      "                                     'BitsAllocated': 16,\n",
      "                                     'BitsStored': 12,\n",
      "                                     'CardiacNumberOfImages': 0,\n",
      "                                     'Columns': 256,\n",
      "                                     'ContentDate': '20050623',\n",
      "                                     'ContentTime': '083051',\n",
      "                                     'DeviceSerialNumber': '000000209526SMMR',\n",
      "                                     'EchoNumbers': 1,\n",
      "                                     'EchoTime': 91.2,\n",
      "                                     'EchoTrainLength': 9,\n",
      "                                     'FlipAngle': 90,\n",
      "                                     'FrameOfReferenceUID': '1.2.840.113619.2.176.3596.6688930.8424.1119539805.641',\n",
      "                                     'HeartRate': 0,\n",
      "                                     'HighBit': 11,\n",
      "                                     'ImageOrientationPatient': [1,\n",
      "                                                                 0,\n",
      "                                                                 0,\n",
      "                                                                 0,\n",
      "                                                                 0,\n",
      "                                                                 0],\n",
      "                                     'ImagePositionPatient': [-118, -130, -52],\n",
      "                                     'ImageType': ['ORIGINAL',\n",
      "                                                   'PRIMARY',\n",
      "                                                   'OTHER'],\n",
      "                                     'ImagedNucleus': '1H',\n",
      "                                     'ImagesInAcquisition': 53,\n",
      "                                     'ImagingFrequency': 63.840478,\n",
      "                                     'InPlanePhaseEncodingDirection': 'ROW',\n",
      "                                     'InstanceNumber': 13,\n",
      "                                     'InstitutionName': 'MEMORIAL MEDICAL '\n",
      "                                                        'CENTER',\n",
      "                                     'InversionTime': 0,\n",
      "                                     'LargestImagePixelValue': 1093,\n",
      "                                     'MRAcquisitionType': '2D',\n",
      "                                     'MagneticFieldStrength': 1.5,\n",
      "                                     'Manufacturer': 'GE MEDICAL SYSTEMS',\n",
      "                                     'ManufacturerModelName': 'SIGNA EXCITE',\n",
      "                                     'Modality': 'MR',\n",
      "                                     'NameOfPhysiciansReadingStudy': 'SGMF OP',\n",
      "                                     'NumberOfAverages': 2,\n",
      "                                     'OperatorsName': 'J',\n",
      "                                     'PatientAge': '029Y',\n",
      "                                     'PatientBirthDate': '19750710',\n",
      "                                     'PatientID': '737178',\n",
      "                                     'PatientName': 'GEN U2787g S01852 10651',\n",
      "                                     'PatientPosition': 'HFS',\n",
      "                                     'PatientSex': 'F',\n",
      "                                     'PatientWeight': 115.666,\n",
      "                                     'PercentPhaseFieldOfView': 75,\n",
      "                                     'PercentSampling': 100,\n",
      "                                     'PhotometricInterpretation': 'MONOCHROME2',\n",
      "                                     'PixelBandwidth': 122.109,\n",
      "                                     'PixelPaddingValue': 0,\n",
      "                                     'PixelRepresentation': 1,\n",
      "                                     'PixelSpacing': [0, 0],\n",
      "                                     'ProtocolName': 'NEURORx RES  BRAIN/4',\n",
      "                                     'ReceiveCoilName': 'HEAD',\n",
      "                                     'ReconstructionDiameter': 250,\n",
      "                                     'ReferringPhysicianName': '',\n",
      "                                     'RepetitionTime': 5116.66,\n",
      "                                     'Rows': 256,\n",
      "                                     'SAR': 0.0305,\n",
      "                                     'SOPClassUID': '1.2.840.10008.5.1.4.1.1.4',\n",
      "                                     'SOPInstanceUID': '1.2.840.113619.2.176.3596.6688930.8149.1119540053.986',\n",
      "                                     'SamplesPerPixel': 1,\n",
      "                                     'ScanOptions': ['SAT_GEMS',\n",
      "                                                     'TRF_GEMS',\n",
      "                                                     'SP'],\n",
      "                                     'ScanningSequence': 'SE',\n",
      "                                     'SequenceVariant': 'SK',\n",
      "                                     'SeriesDate': '20050623',\n",
      "                                     'SeriesDescription': 'Ax T2W FSE ',\n",
      "                                     'SeriesInstanceUID': '1.2.840.113619.2.176.3596.6688930.8424.1119539805.644',\n",
      "                                     'SeriesNumber': 3,\n",
      "                                     'SeriesTime': '083051',\n",
      "                                     'SliceLocation': -52.71968079,\n",
      "                                     'SliceThickness': 3,\n",
      "                                     'SmallestImagePixelValue': 0,\n",
      "                                     'SoftwareVersions': ['12',\n",
      "                                                          'LX',\n",
      "                                                          'MR Software '\n",
      "                                                          'release:12.0_M3A_0511.a'],\n",
      "                                     'SpacingBetweenSlices': 3,\n",
      "                                     'SpecificCharacterSet': 'ISO_IR 100',\n",
      "                                     'StationName': 'GEMSOW',\n",
      "                                     'StudyDate': '20050623',\n",
      "                                     'StudyDescription': 'BRAIN',\n",
      "                                     'StudyID': '21671',\n",
      "                                     'StudyInstanceUID': '1.2.840.113619.2.176.3596.6688930.8424.1119539805.642',\n",
      "                                     'StudyTime': '082053',\n",
      "                                     'TriggerWindow': 0,\n",
      "                                     'VariableFlipAngleFlag': 'N',\n",
      "                                     'WindowCenter': 546,\n",
      "                                     'WindowWidth': 1093},\n",
      "                            'modality': 'MR',\n",
      "                            'name': 'A.zip'}],\n",
      "                 'instrument': 'MR',\n",
      "                 'label': 'Ax T2W FSE ',\n",
      "                 'metadata': {'AccessionNumber': '039208195',\n",
      "                              'AcquisitionDate': '20050623',\n",
      "                              'AcquisitionMatrix': [0, 256, 256, 0],\n",
      "                              'AcquisitionNumber': 1,\n",
      "                              'AcquisitionTime': '083051',\n",
      "                              'AdditionalPatientHistory': 'RESEARCH PT',\n",
      "                              'AngioFlag': 'N',\n",
      "                              'BitsAllocated': 16,\n",
      "                              'BitsStored': 12,\n",
      "                              'CardiacNumberOfImages': 0,\n",
      "                              'Columns': 256,\n",
      "                              'ContentDate': '20050623',\n",
      "                              'ContentTime': '083051',\n",
      "                              'DeviceSerialNumber': '000000209526SMMR',\n",
      "                              'EchoNumbers': 1,\n",
      "                              'EchoTime': 91.2,\n",
      "                              'EchoTrainLength': 9,\n",
      "                              'FlipAngle': 90,\n",
      "                              'FrameOfReferenceUID': '1.2.840.113619.2.176.3596.6688930.8424.1119539805.641',\n",
      "                              'HeartRate': 0,\n",
      "                              'HighBit': 11,\n",
      "                              'ImageOrientationPatient': [1, 0, 0, 0, 0, 0],\n",
      "                              'ImagePositionPatient': [-118, -130, -52],\n",
      "                              'ImageType': ['ORIGINAL', 'PRIMARY', 'OTHER'],\n",
      "                              'ImagedNucleus': '1H',\n",
      "                              'ImagesInAcquisition': 53,\n",
      "                              'ImagingFrequency': 63.840478,\n",
      "                              'InPlanePhaseEncodingDirection': 'ROW',\n",
      "                              'InstanceNumber': 13,\n",
      "                              'InstitutionName': 'MEMORIAL MEDICAL CENTER',\n",
      "                              'InversionTime': 0,\n",
      "                              'LargestImagePixelValue': 1093,\n",
      "                              'MRAcquisitionType': '2D',\n",
      "                              'MagneticFieldStrength': 1.5,\n",
      "                              'Manufacturer': 'GE MEDICAL SYSTEMS',\n",
      "                              'ManufacturerModelName': 'SIGNA EXCITE',\n",
      "                              'Modality': 'MR',\n",
      "                              'NameOfPhysiciansReadingStudy': 'SGMF OP',\n",
      "                              'NumberOfAverages': 2,\n",
      "                              'OperatorsName': 'J',\n",
      "                              'PatientAge': '029Y',\n",
      "                              'PatientBirthDate': '19750710',\n",
      "                              'PatientID': '737178',\n",
      "                              'PatientName': 'GEN U2787g S01852 10651',\n",
      "                              'PatientPosition': 'HFS',\n",
      "                              'PatientSex': 'F',\n",
      "                              'PatientWeight': 115.666,\n",
      "                              'PercentPhaseFieldOfView': 75,\n",
      "                              'PercentSampling': 100,\n",
      "                              'PhotometricInterpretation': 'MONOCHROME2',\n",
      "                              'PixelBandwidth': 122.109,\n",
      "                              'PixelPaddingValue': 0,\n",
      "                              'PixelRepresentation': 1,\n",
      "                              'PixelSpacing': [0, 0],\n",
      "                              'ProtocolName': 'NEURORx RES  BRAIN/4',\n",
      "                              'ReceiveCoilName': 'HEAD',\n",
      "                              'ReconstructionDiameter': 250,\n",
      "                              'ReferringPhysicianName': '',\n",
      "                              'RepetitionTime': 5116.66,\n",
      "                              'Rows': 256,\n",
      "                              'SAR': 0.0305,\n",
      "                              'SOPClassUID': '1.2.840.10008.5.1.4.1.1.4',\n",
      "                              'SOPInstanceUID': '1.2.840.113619.2.176.3596.6688930.8149.1119540053.986',\n",
      "                              'SamplesPerPixel': 1,\n",
      "                              'ScanOptions': ['SAT_GEMS', 'TRF_GEMS', 'SP'],\n",
      "                              'ScanningSequence': 'SE',\n",
      "                              'SequenceVariant': 'SK',\n",
      "                              'SeriesDate': '20050623',\n",
      "                              'SeriesDescription': 'Ax T2W FSE ',\n",
      "                              'SeriesInstanceUID': '1.2.840.113619.2.176.3596.6688930.8424.1119539805.644',\n",
      "                              'SeriesNumber': 3,\n",
      "                              'SeriesTime': '083051',\n",
      "                              'SliceLocation': -52.71968079,\n",
      "                              'SliceThickness': 3,\n",
      "                              'SmallestImagePixelValue': 0,\n",
      "                              'SoftwareVersions': ['12',\n",
      "                                                   'LX',\n",
      "                                                   'MR Software '\n",
      "                                                   'release:12.0_M3A_0511.a'],\n",
      "                              'SpacingBetweenSlices': 3,\n",
      "                              'SpecificCharacterSet': 'ISO_IR 100',\n",
      "                              'StationName': 'GEMSOW',\n",
      "                              'StudyDate': '20050623',\n",
      "                              'StudyDescription': 'BRAIN',\n",
      "                              'StudyID': '21671',\n",
      "                              'StudyInstanceUID': '1.2.840.113619.2.176.3596.6688930.8424.1119539805.642',\n",
      "                              'StudyTime': '082053',\n",
      "                              'TriggerWindow': 0,\n",
      "                              'VariableFlipAngleFlag': 'N',\n",
      "                              'WindowCenter': 546,\n",
      "                              'WindowWidth': 1093},\n",
      "                 'tags': ['error'],\n",
      "                 'timestamp': '2005-06-23T08:30:51-05:00'},\n",
      " 'session': {'label': '21671',\n",
      "             'operator': 'J',\n",
      "             'subject': {'age': 915170400,\n",
      "                         'lastname': 'GEN U2787g S01852 10651',\n",
      "                         'sex': 'female'},\n",
      "             'timestamp': '2005-06-23T08:20:53-05:00'}}\n"
     ]
    }
   ],
   "source": [
    "# Check for input file path\n",
    "if not os.path.exists(zip_file_path):\n",
    "    log.debug('could not find %s' % zip_file_path)\n",
    "    log.debug('checking input directory ...')\n",
    "    if os.path.exists(os.path.join('/input', zip_file_path)):\n",
    "        zip_file_path = os.path.join('/input', zip_file_path)\n",
    "        log.debug('found %s' % zip_file_path)\n",
    "\n",
    "if not outbase:\n",
    "    outbase = '/flywheel/v0/output'\n",
    "    log.info('setting outbase to %s' % outbase)\n",
    "\n",
    "# Extract the last file in the zip to /tmp/ and read it\n",
    "dcm = []\n",
    "if zipfile.is_zipfile(zip_file_path):\n",
    "    zip = zipfile.ZipFile(zip_file_path)\n",
    "    num_files = len(zip.namelist())\n",
    "    for n in range((num_files - 1), -1, -1):\n",
    "        dcm_path = zip.extract(zip.namelist()[n], '/tmp')\n",
    "        if os.path.isfile(dcm_path):\n",
    "            try:\n",
    "                log.info('reading %s' % dcm_path)\n",
    "                dcm = pydicom.read_file(dcm_path)\n",
    "                # Here we check for the Raw Data Storage SOP Class, if there\n",
    "                # are other pydicom files in the zip then we read the next one,\n",
    "                # if this is the only class of pydicom in the file, we accept\n",
    "                # our fate and move on.\n",
    "                if dcm.get('SOPClassUID') == 'Raw Data Storage' and n != range((num_files - 1), -1, -1)[-1]:\n",
    "                    continue\n",
    "                else:\n",
    "                    break\n",
    "            except:\n",
    "                pass\n",
    "        else:\n",
    "            log.warning('%s does not exist!' % dcm_path)\n",
    "else:\n",
    "    log.info('Not a zip. Attempting to read %s directly' % os.path.basename(zip_file_path))\n",
    "    dcm = pydicom.read_file(zip_file_path)\n",
    "\n",
    "if not dcm:\n",
    "    log.warning('dcm is empty!!!')\n",
    "    os.sys.exit(1)\n",
    "\n",
    "# Build metadata\n",
    "metadata = {}\n",
    "\n",
    "# Session metadata\n",
    "metadata['session'] = {}\n",
    "session_timestamp, acquisition_timestamp = get_timestamp(dcm, timezone);\n",
    "if session_timestamp:\n",
    "    metadata['session']['timestamp'] = session_timestamp\n",
    "if hasattr(dcm, 'OperatorsName') and dcm.get('OperatorsName'):\n",
    "    metadata['session']['operator'] = format_string(dcm.get('OperatorsName'))\n",
    "session_label = get_session_label(dcm)\n",
    "if session_label:\n",
    "    metadata['session']['label'] = session_label\n",
    "\n",
    "# Subject Metadata\n",
    "metadata['session']['subject'] = {}\n",
    "if hasattr(dcm, 'PatientSex') and get_sex_string(dcm.get('PatientSex')):\n",
    "    metadata['session']['subject']['sex'] = get_sex_string(dcm.get('PatientSex'))\n",
    "if hasattr(dcm, 'PatientAge') and dcm.get('PatientAge'):\n",
    "    try:\n",
    "        age = parse_patient_age(dcm.get('PatientAge'))\n",
    "        if age:\n",
    "            metadata['session']['subject']['age'] = int(age)\n",
    "    except:\n",
    "        pass\n",
    "if hasattr(dcm, 'PatientName') and dcm.get('PatientName').given_name:\n",
    "    # If the first name or last name field has a space-separated string, and one or the other field is not\n",
    "    # present, then we assume that the operator put both first and last names in that one field. We then\n",
    "    # parse that field to populate first and last name.\n",
    "    metadata['session']['subject']['firstname'] = str(format_string(dcm.get('PatientName').given_name))\n",
    "    if not dcm.get('PatientName').family_name:\n",
    "        name = format_string(dcm.get('PatientName').given_name.split(' '))\n",
    "        if len(name) == 2:\n",
    "            first = name[0]\n",
    "            last = name[1]\n",
    "            metadata['session']['subject']['lastname'] = str(last)\n",
    "            metadata['session']['subject']['firstname'] = str(first)\n",
    "if hasattr(dcm, 'PatientName') and dcm.get('PatientName').family_name:\n",
    "    metadata['session']['subject']['lastname'] = str(format_string(dcm.get('PatientName').family_name))\n",
    "    if not dcm.get('PatientName').given_name:\n",
    "        name = format_string(dcm.get('PatientName').family_name.split(' '))\n",
    "        if len(name) == 2:\n",
    "            first = name[0]\n",
    "            last = name[1]\n",
    "            metadata['session']['subject']['lastname'] = str(last)\n",
    "            metadata['session']['subject']['firstname'] = str(first)\n",
    "\n",
    "# File classification\n",
    "pydicom_file = {}\n",
    "pydicom_file['name'] = os.path.basename(zip_file_path)\n",
    "pydicom_file['modality'] = format_string(dcm.get('Modality', 'MR'))\n",
    "\n",
    "# Acquisition metadata\n",
    "metadata['acquisition'] = {}\n",
    "if hasattr(dcm, 'Modality') and dcm.get('Modality'):\n",
    "    metadata['acquisition']['instrument'] = format_string(dcm.get('Modality'))\n",
    "\n",
    "series_desc = format_string(dcm.get('SeriesDescription', ''))\n",
    "if series_desc:\n",
    "    metadata['acquisition']['label'] = series_desc\n",
    "\n",
    "if acquisition_timestamp:\n",
    "    metadata['acquisition']['timestamp'] = acquisition_timestamp\n",
    "\n",
    "# Acquisition metadata from pydicom header\n",
    "pydicom_file['info'] = get_pydicom_header(dcm)\n",
    "\n",
    "# Validate header data\n",
    "error_filepath = os.path.join(output_folder, 'error.log.json')\n",
    "validation_errors = validate_against_template(pydicom_file['info'], json_template, error_filepath)\n",
    "if validation_errors:\n",
    "    metadata['acquisition']['tags'] = ['error']\n",
    "\n",
    "# Append the pydicom_file to the files array\n",
    "metadata['acquisition']['files'] = [pydicom_file]\n",
    "\n",
    "# Acquisition metadata from pydicom header\n",
    "metadata['acquisition']['metadata'] = get_pydicom_header(dcm)\n",
    "if dcm.get('Manufacturer') == 'SIEMENS':\n",
    "    csa_header = get_csa_header(dcm)\n",
    "    if csa_header:\n",
    "        metadata['acquisition']['metadata']['CSAHeader'] = csa_header\n",
    "\n",
    "# Write out the metadata to file (.metadata.json)\n",
    "metafile_outname = os.path.join(os.path.dirname(outbase), '.metadata.json')\n",
    "with open(metafile_outname, 'w') as metafile:\n",
    "    json.dump(metadata, metafile, separators=(', ', ': '), sort_keys=True, indent=4)\n",
    "\n",
    "# Show the metadata\n",
    "pprint(metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "arrays must all be same length",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-32be71334f23>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmetadata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'acquisition'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'files'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'info'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mfrom_dict\u001b[0;34m(cls, data, orient, dtype, columns)\u001b[0m\n\u001b[1;32m    983\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'only recognize index or columns for orient'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    984\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 985\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    986\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    987\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mto_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morient\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'dict'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minto\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[1;32m    346\u001b[0m                                  dtype=dtype, copy=copy)\n\u001b[1;32m    347\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 348\u001b[0;31m             \u001b[0mmgr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_init_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    349\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMaskedArray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    350\u001b[0m             \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmrecords\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mmrecords\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_init_dict\u001b[0;34m(self, data, index, columns, dtype)\u001b[0m\n\u001b[1;32m    457\u001b[0m             \u001b[0marrays\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mkeys\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    458\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 459\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_arrays_to_mgr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_names\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    460\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    461\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_init_ndarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_arrays_to_mgr\u001b[0;34m(arrays, arr_names, index, columns, dtype)\u001b[0m\n\u001b[1;32m   7354\u001b[0m     \u001b[0;31m# figure out the index, if necessary\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   7355\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mindex\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 7356\u001b[0;31m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextract_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   7357\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   7358\u001b[0m     \u001b[0;31m# don't force copy because getting jammed in an ndarray anyway\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mextract_index\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m   7400\u001b[0m             \u001b[0mlengths\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraw_lengths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   7401\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlengths\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 7402\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'arrays must all be same length'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   7403\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   7404\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhave_dicts\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: arrays must all be same length"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.DataFrame.from_dict(metadata['acquisition']['files'][0]['info'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import all dcm file headers\n",
    "\n",
    "I'd like a way to import all headers as a dataframe in order to do validation across files. Pandas does not accept lists as dictionary values, so just non-sequence for now.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assign_type_pd(s):\n",
    "    \"\"\"\n",
    "    Sets the type of a given input.\n",
    "    \"\"\"\n",
    "    if type(s) == pydicom.valuerep.PersonName or type(s) == pydicom.valuerep.PersonName3 or type(s) == pydicom.valuerep.PersonNameBase:\n",
    "        return format_string(s)\n",
    "    else:\n",
    "        s = str(s)\n",
    "        try:\n",
    "            return int(s)\n",
    "        except ValueError:\n",
    "            try:\n",
    "                return float(s)\n",
    "            except ValueError:\n",
    "                return format_string(s)\n",
    "def dicom_header_to_pd(dcm):\n",
    "    # Extract the header values\n",
    "    header = {}\n",
    "    exclude_tags = ['[Unknown]', \n",
    "                    'PixelData', \n",
    "                    'Pixel Data',  \n",
    "                    '[User defined data]', \n",
    "                    '[Protocol Data Block (compressed)]', \n",
    "                    '[Histogram tables]', \n",
    "                    '[Unique image iden]']\n",
    "    tags = dcm.dir()\n",
    "    for tag in tags:\n",
    "        try:\n",
    "            if (tag not in exclude_tags) and ( type(dcm.get(tag)) != pydicom.sequence.Sequence ):\n",
    "                value = dcm.get(tag)\n",
    "                if value or value == 0: # Some values are zero\n",
    "                    # Put the value in the header\n",
    "                    if type(value) == str and len(value) < 10240: # Max pydicom field length\n",
    "                        header[tag] = [format_string(value)]\n",
    "                    else:\n",
    "                        header[tag] = [assign_type_pd(value)]\n",
    "                        \n",
    "                else:\n",
    "                    log.debug('No value found for tag: ' + tag)\n",
    "        except:\n",
    "            log.debug('Failed to get ' + tag)\n",
    "            pass\n",
    "    dataframe = pd.DataFrame.from_dict(header)\n",
    "    return dataframe\n",
    "    \n",
    "    #return header\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AccessionNumber</th>\n",
       "      <th>AcquisitionDate</th>\n",
       "      <th>AcquisitionMatrix</th>\n",
       "      <th>AcquisitionNumber</th>\n",
       "      <th>AcquisitionTime</th>\n",
       "      <th>AdditionalPatientHistory</th>\n",
       "      <th>AngioFlag</th>\n",
       "      <th>BitsAllocated</th>\n",
       "      <th>BitsStored</th>\n",
       "      <th>CardiacNumberOfImages</th>\n",
       "      <th>...</th>\n",
       "      <th>StationName</th>\n",
       "      <th>StudyDate</th>\n",
       "      <th>StudyDescription</th>\n",
       "      <th>StudyID</th>\n",
       "      <th>StudyInstanceUID</th>\n",
       "      <th>StudyTime</th>\n",
       "      <th>TriggerWindow</th>\n",
       "      <th>VariableFlipAngleFlag</th>\n",
       "      <th>WindowCenter</th>\n",
       "      <th>WindowWidth</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>039208195</td>\n",
       "      <td>20050623</td>\n",
       "      <td>[0, 256, 256, 0]</td>\n",
       "      <td>1</td>\n",
       "      <td>083051</td>\n",
       "      <td>RESEARCH PT</td>\n",
       "      <td>N</td>\n",
       "      <td>16</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>GEMSOW</td>\n",
       "      <td>20050623</td>\n",
       "      <td>BRAIN</td>\n",
       "      <td>21671</td>\n",
       "      <td>1.2.840.113619.2.176.3596.6688930.8424.1119539...</td>\n",
       "      <td>082053</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>546</td>\n",
       "      <td>1093</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows  88 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  AccessionNumber AcquisitionDate AcquisitionMatrix  AcquisitionNumber  \\\n",
       "0       039208195        20050623  [0, 256, 256, 0]                  1   \n",
       "\n",
       "  AcquisitionTime AdditionalPatientHistory AngioFlag  BitsAllocated  \\\n",
       "0          083051              RESEARCH PT         N             16   \n",
       "\n",
       "   BitsStored  CardiacNumberOfImages     ...       StationName StudyDate  \\\n",
       "0          12                      0     ...            GEMSOW  20050623   \n",
       "\n",
       "  StudyDescription StudyID                                   StudyInstanceUID  \\\n",
       "0            BRAIN   21671  1.2.840.113619.2.176.3596.6688930.8424.1119539...   \n",
       "\n",
       "   StudyTime  TriggerWindow  VariableFlipAngleFlag WindowCenter  WindowWidth  \n",
       "0     082053              0                      N          546         1093  \n",
       "\n",
       "[1 rows x 88 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "header = dicom_header_to_pd(dcm)\n",
    "header"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/tmp/A/A:Z07\n",
      "/tmp/A/A:Z09\n",
      "/tmp/A/A:Z08\n",
      "/tmp/A/A:Z06\n",
      "/tmp/A/A:Z01\n",
      "/tmp/A/A:Z23\n",
      "/tmp/A/A:Z24\n",
      "/tmp/A/A:Z12\n",
      "/tmp/A/A:Z15\n",
      "/tmp/A/A:Z14\n",
      "/tmp/A/A:Z13\n",
      "/tmp/A/A:Z25\n",
      "/tmp/A/A:Z22\n",
      "/tmp/A/A:Z04\n",
      "/tmp/A/A:Z03\n",
      "/tmp/A/A:Z02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:U2787g:/tmp/A does not exist!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/tmp/A/A:Z05\n",
      "/tmp/A/A:Z18\n",
      "/tmp/A/A:Z20\n",
      "/tmp/A/A:Z16\n",
      "/tmp/A/A:Z11\n",
      "/tmp/A/A:Z10\n",
      "/tmp/A/A:Z17\n",
      "/tmp/A/A:Z21\n",
      "/tmp/A/A:Z19\n",
      "/tmp/A\n"
     ]
    }
   ],
   "source": [
    "df_list = []\n",
    "dcm = []\n",
    "if zipfile.is_zipfile(zip_file_path):\n",
    "    zip = zipfile.ZipFile(zip_file_path)\n",
    "    num_files = len(zip.namelist())\n",
    "    for n in range((num_files - 1), -1, -1):\n",
    "        dcm_path = zip.extract(zip.namelist()[n], '/tmp')\n",
    "        print(dcm_path)\n",
    "        if os.path.isfile(dcm_path):\n",
    "            try:\n",
    "                log.info('reading %s' % dcm_path)\n",
    "                dcm = pydicom.read_file(dcm_path)\n",
    "                # Here we check for the Raw Data Storage SOP Class, if there\n",
    "                # are other pydicom files in the zip then we read the next one,\n",
    "                # if this is the only class of pydicom in the file, we accept\n",
    "                # our fate and move on.\n",
    "                if dcm.get('SOPClassUID') == 'Raw Data Storage' and n != range((num_files - 1), -1, -1)[-1]:\n",
    "                    continue\n",
    "                else:\n",
    "                    header = None\n",
    "                    header = dicom_header_to_pd(dcm)\n",
    "                    df_list.append(header)\n",
    "            except:\n",
    "                pass\n",
    "        else:\n",
    "            log.warning('%s does not exist!' % dcm_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_list = []\n",
    "dcm = []\n",
    "for zip_file in zipfile.ZipFile(zip_file_path).namelist():\n",
    "    dcm_path = zip.extract(zip_file, '/tmp')\n",
    "    if os.path.isfile(dcm_path):\n",
    "        try:\n",
    "            log.info('reading %s' % dcm_path)\n",
    "            dcm = pydicom.read_file(dcm_path)\n",
    "            # Here we check for the Raw Data Storage SOP Class, if there\n",
    "            # are other pydicom files in the zip then we read the next one,\n",
    "            # if this is the only class of pydicom in the file, we accept\n",
    "            # our fate and move on.\n",
    "            if dcm.get('SOPClassUID') == 'Raw Data Storage' and n != range((num_files - 1), -1, -1)[-1]:\n",
    "                continue\n",
    "            else:\n",
    "                header = None\n",
    "                header = dicom_header_to_pd(dcm)\n",
    "                df_list.append(header)\n",
    "        except:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat(df_list,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    ['1', '-0', '0', '-0', '0.999998', '0.00219732']\n",
      "0    ['1', '-0', '0', '-0', '0.999998', '0.00219732']\n",
      "0    ['1', '-0', '0', '-0', '0.999998', '0.00219733']\n",
      "0    ['1', '-0', '0', '-0', '0.999998', '0.00219732']\n",
      "0    ['1', '-0', '0', '-0', '0.999998', '0.00219732']\n",
      "0    ['1', '-0', '0', '-0', '0.999998', '0.00219733']\n",
      "0    ['1', '-0', '0', '-0', '0.999998', '0.00219732']\n",
      "0    ['1', '-0', '0', '-0', '0.999998', '0.00219733']\n",
      "0    ['1', '-0', '0', '-0', '0.999998', '0.00219732']\n",
      "0    ['1', '-0', '0', '-0', '0.999998', '0.00219732']\n",
      "0    ['1', '-0', '0', '-0', '0.999998', '0.00219732']\n",
      "0    ['1', '-0', '0', '-0', '0.999998', '0.00219732']\n",
      "0    ['1', '-0', '0', '-0', '0.999998', '0.00219732']\n",
      "0    ['1', '-0', '0', '-0', '0.999998', '0.00219732']\n",
      "0    ['1', '-0', '0', '-0', '0.999998', '0.00219732']\n",
      "0    ['1', '-0', '0', '-0', '0.999998', '0.00219733']\n",
      "0    ['1', '-0', '0', '-0', '0.999998', '0.00219733']\n",
      "0    ['1', '-0', '0', '-0', '0.999998', '0.00219732']\n",
      "0    ['1', '-0', '0', '-0', '0.999998', '0.00219732']\n",
      "0    ['1', '-0', '0', '-0', '0.999998', '0.00219732']\n",
      "0    ['1', '-0', '0', '-0', '0.999998', '0.00219732']\n",
      "0    ['1', '-0', '0', '-0', '0.999998', '0.00219732']\n",
      "0    ['1', '-0', '0', '-0', '0.999998', '0.00219732']\n",
      "0    ['1', '-0', '0', '-0', '0.999998', '0.00219732']\n",
      "0    ['1', '-0', '0', '-0', '0.999998', '0.00219732']\n",
      "Name: ImageOrientationPatient, dtype: object\n"
     ]
    }
   ],
   "source": [
    "#print(df.nunique())\n",
    "for col in df.columns:\n",
    "    if len(df[col].unique()) == 2:\n",
    "        print(df[col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    ['1', '-0', '0', '-0', '0.999998', '0.00219732']\n",
       "0    ['1', '-0', '0', '-0', '0.999998', '0.00219732']\n",
       "0    ['1', '-0', '0', '-0', '0.999998', '0.00219733']\n",
       "0    ['1', '-0', '0', '-0', '0.999998', '0.00219732']\n",
       "0    ['1', '-0', '0', '-0', '0.999998', '0.00219732']\n",
       "0    ['1', '-0', '0', '-0', '0.999998', '0.00219733']\n",
       "0    ['1', '-0', '0', '-0', '0.999998', '0.00219732']\n",
       "0    ['1', '-0', '0', '-0', '0.999998', '0.00219733']\n",
       "0    ['1', '-0', '0', '-0', '0.999998', '0.00219732']\n",
       "0    ['1', '-0', '0', '-0', '0.999998', '0.00219732']\n",
       "0    ['1', '-0', '0', '-0', '0.999998', '0.00219732']\n",
       "0    ['1', '-0', '0', '-0', '0.999998', '0.00219732']\n",
       "0    ['1', '-0', '0', '-0', '0.999998', '0.00219732']\n",
       "0    ['1', '-0', '0', '-0', '0.999998', '0.00219732']\n",
       "0    ['1', '-0', '0', '-0', '0.999998', '0.00219732']\n",
       "0    ['1', '-0', '0', '-0', '0.999998', '0.00219733']\n",
       "0    ['1', '-0', '0', '-0', '0.999998', '0.00219733']\n",
       "0    ['1', '-0', '0', '-0', '0.999998', '0.00219732']\n",
       "0    ['1', '-0', '0', '-0', '0.999998', '0.00219732']\n",
       "0    ['1', '-0', '0', '-0', '0.999998', '0.00219732']\n",
       "0    ['1', '-0', '0', '-0', '0.999998', '0.00219732']\n",
       "0    ['1', '-0', '0', '-0', '0.999998', '0.00219732']\n",
       "0    ['1', '-0', '0', '-0', '0.999998', '0.00219732']\n",
       "0    ['1', '-0', '0', '-0', '0.999998', '0.00219732']\n",
       "0    ['1', '-0', '0', '-0', '0.999998', '0.00219732']\n",
       "Name: ImageOrientationPatient, dtype: object"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[0,'ImageOrientationPatient']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
